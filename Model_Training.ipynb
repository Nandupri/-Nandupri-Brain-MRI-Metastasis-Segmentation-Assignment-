{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This notebook covers the training process for the Nested U-Net and Attention U-Net models for brain MRI metastasis segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from models.attention_unet import AttentionUNet\n",
    "from models.nested_unet import NestedUNet\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "Define a dataset class to load and preprocess the images and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.images[idx])\n",
    "        image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
    "        mask_name = os.path.join(self.mask_dir, self.images[idx])\n",
    "        mask = cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation and Loading\n",
    "Set up data augmentation and data loaders for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, RandomRotate90, Normalize, Resize\n",
    "\n",
    "def get_transform():\n",
    "    return Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        VerticalFlip(p=0.5),\n",
    "        RandomRotate90(p=0.5),\n",
    "        Resize(height=544, width=640, p=1.0),\n",
    "        Normalize(mean=0.5, std=0.5, p=1.0)\n",
    "    ])\n",
    "\n",
    "# Define directories\n",
    "processed_images_dir = 'data/processed/images/'\n",
    "processed_masks_dir = 'data/processed/masks/'\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "transform = get_transform()\n",
    "dataset = BrainMRIDataset(processed_images_dir, processed_masks_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Function\n",
    "Define the function to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=25, learning_rate=0.001):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, masks in train_loader:\n",
    "            images = images.to(device).float()\n",
    "            masks = masks.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks.unsqueeze(1))  # Add channel dimension\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {train_loss:.4f}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device).float()\n",
    "                masks = masks.to(device).float()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks.unsqueeze(1))\n",
    "                val_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "        val_loss /= len(val_loader)\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Models\n",
    "Now let's train both the Nested U-Net and Attention U-Net models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Nested U-Net\n",
    "nested_unet_model = NestedUNet(in_channels=1, out_channels=1).to(device)\n",
    "print('Training Nested U-Net...')\n",
    "nested_unet_model = train_model(nested_unet_model, train_loader, val_loader, num_epochs=25)\n",
    "\n",
    "# Save Nested U-Net model\n",
    "torch.save(nested_unet_model.state_dict(), 'trained_models/nested_unet.pth')\n",
    "\n",
    "# Train Attention U-Net\n",
    "attention_unet_model = AttentionUNet(in_channels=1, out_channels=1).to(device)\n",
    "print('Training Attention U-Net...')\n",
    "attention_unet_model = train_model(attention_unet_model, train_loader, val_loader, num_epochs=25)\n",
    "\n",
    "# Save Attention U-Net model\n",
    "torch.save(attention_unet_model.state_dict(), 'trained_models/attention_unet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we trained the Nested U-Net and Attention U-Net models on the brain MRI dataset for metastasis segmentation. The models are saved for later evaluation and deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language":
